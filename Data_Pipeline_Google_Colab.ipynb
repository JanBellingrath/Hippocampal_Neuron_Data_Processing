{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanBellingrath/Hippocampal_Neuron_Data_Processing/blob/main/Data_Pipeline_Google_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6BSNosCEeaE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from os.path import join\n",
        "import dask\n",
        "import numpy as np  \n",
        "import pandas as pd\n",
        "import scipy\n",
        "from scipy.io import loadmat\n",
        "from collections import namedtuple\n",
        "import mrestimator as mre\n",
        "\n",
        "import loren_frank_data_processing\n",
        "from loren_frank_data_processing.core import get_data_filename, logger, get_epochs, get_data_structure\n",
        "from loren_frank_data_processing.tetrodes import  convert_tetrode_epoch_to_dataframe, get_LFP_dataframe, _get_tetrode_id\n",
        "from loren_frank_data_processing.neurons import get_neuron_info_path, get_spikes_dataframe, make_neuron_dataframe, convert_neuron_epoch_to_dataframe, _add_to_dict, _get_neuron_id\n",
        "import loren_frank_data_processing.core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuadrDQzFKrT"
      },
      "outputs": [],
      "source": [
        "#modified functions from loren_frank_dataprocessing, where changes largely relate to data-processing in GoogleColab; + some minor bug fixes.\n",
        "\n",
        "def get_data_filename_modified(animal, day, file_type):\n",
        "    '''Returns the Matlab file name assuming it is in the Raw Data\n",
        "    directory.\n",
        "    Parameters\n",
        "    ----------\n",
        "    animal : namedtuple\n",
        "        First element is the directory where the animal's data is located.\n",
        "        The second element is the animal shortened name.\n",
        "    day : int\n",
        "        Day of recording\n",
        "    file_type : str\n",
        "        Data structure name (e.g. linpos, dio)\n",
        "    Returns\n",
        "    -------\n",
        "    filename : str\n",
        "        Path to data file\n",
        "    '''\n",
        "    filename = '{animal.short_name}{file_type}{day:02d}.mat'.format(\n",
        "        animal=animal,\n",
        "        file_type=file_type,\n",
        "        day=day)\n",
        "    return filename \n",
        "\n",
        "\n",
        "def get_spikes_dataframe(neuron_key, animals):\n",
        "    '''Spike times for a particular neuron.\n",
        "    Parameters\n",
        "    ----------\n",
        "    neuron_key : tuple\n",
        "        Unique key identifying that neuron. Elements of the tuple are\n",
        "        (animal_short_name, day, epoch, tetrode_number, neuron_number).\n",
        "        Key can be retrieved from `make_neuron_dataframe` function.\n",
        "    animals : dict of named-tuples\n",
        "        Dictionary containing information about the directory for each\n",
        "        animal. The key is the animal_short_name.\n",
        "    Returns\n",
        "    -------\n",
        "    spikes_dataframe : pandas.DataFrame\n",
        "    '''\n",
        "    animal, day, epoch, tetrode_number, neuron_number = neuron_key\n",
        "    try:\n",
        "        neuron_file = loadmat(\n",
        "            get_data_filename_modified(animals[animal], day, 'spikes'))\n",
        "        print(neuron_file)\n",
        "    except (FileNotFoundError, TypeError):\n",
        "        logger.warning('Failed to load file: {0}'.format(\n",
        "            get_data_filename_modified(animals[animal], day, 'spikes')))\n",
        "    try:\n",
        "        spike_time = neuron_file['spikes'][0, -1][0, epoch - 1][\n",
        "            0, tetrode_number - 1][0, neuron_number - 1][0]['data'][0][\n",
        "            :, 0]\n",
        "        spike_time = pd.TimedeltaIndex(spike_time, unit='s', name='time')\n",
        "    except IndexError:\n",
        "        spike_time = []\n",
        "    return pd.Series(\n",
        "        np.ones_like(spike_time, dtype=int), index=spike_time,\n",
        "        name='{0}_{1:02d}_{2:02}_{3:03}_{4:03}'.format(*neuron_key))\n",
        "\n",
        "\n",
        "def get_LFP_dataframe_modified(tetrode_key, animals):\n",
        "    '''Gets the LFP data for a given epoch and tetrode.\n",
        "    Parameters\n",
        "    ----------\n",
        "    tetrode_key : tuple\n",
        "        Unique key identifying the tetrode. Elements are\n",
        "        (animal_short_name, day, epoch, tetrode_number).\n",
        "    animals : dict of named-tuples\n",
        "        Dictionary containing information about the directory for each\n",
        "        animal. The key is the animal_short_name.\n",
        "    Returns\n",
        "    -------\n",
        "    LFP : pandas dataframe\n",
        "        Contains the electric potential and time\n",
        "    '''\n",
        "    #print(tetrode_key)\n",
        "    #tetrode_key = tuple(tetrode_key.split(\",\"))\n",
        "    #tetrode_key = tetrode_key[1:-1].split(', ')\n",
        "    \n",
        "    try:\n",
        "        lfp_file = loadmat(get_LFP_filename_modified(tetrode_key, animals))\n",
        "        lfp_data = lfp_file['eeg'][0, -1][0, -1][0, -1]\n",
        "        lfp_time = reconstruct_time(\n",
        "            lfp_data['starttime'][0, 0].item(),\n",
        "            lfp_data['data'][0, 0].size,\n",
        "            float(lfp_data['samprate'][0, 0].squeeze()))\n",
        "        return pd.Series(\n",
        "            data=lfp_data['data'][0, 0].squeeze().astype(float),\n",
        "            index=lfp_time,\n",
        "            name='{0}_{1:02d}_{2:02}_{3:03}'.format(*tetrode_key))\n",
        "    except (FileNotFoundError, TypeError):\n",
        "        logger.warning('Failed to load file: {0}'.format(\n",
        "            get_LFP_filename_modified(tetrode_key, animals)))\n",
        "        \n",
        "\n",
        "\n",
        "def make_neuron_dataframe_modified(animals):\n",
        "    '''Information about all recorded neurons such as brain area.\n",
        "    The index of the dataframe corresponds to the unique key for that neuron\n",
        "    and can be used to load spiking information.\n",
        "    Parameters\n",
        "    ----------\n",
        "    animals : dict of named-tuples\n",
        "        Dictionary containing information about the directory for each\n",
        "        animal. The key is the animal_short_name.\n",
        "    Returns\n",
        "    -------\n",
        "    neuron_information : pandas.DataFrame\n",
        "    '''\n",
        "    #neuron_file_names = [(get_neuron_info_path(animals[animal]), animal)\n",
        "     #                    for animal in animals]\n",
        "    neuron_file_names = ['concellinfo.mat', 'Corcellinfo.mat']\n",
        "    neuron_data = [(loadmat(file_name), animal_name) for animal_name, file_name in zip(animals.keys(), neuron_file_names)]\n",
        "\n",
        "    return pd.concat([\n",
        "        convert_neuron_epoch_to_dataframe(\n",
        "            epoch, animal, day_ind + 1, epoch_ind + 1)\n",
        "        for cellfile, animal in neuron_data\n",
        "        for day_ind, day in enumerate(cellfile['cellinfo'].T)\n",
        "        for epoch_ind, epoch in enumerate(day[0].T)\n",
        "    ]).sort_index()\n",
        "\n",
        "\n",
        "def get_LFP_filename_modified(tetrode_key, animals):\n",
        "    '''Returns a file name for the tetrode file LFP for an epoch.\n",
        "    Parameters\n",
        "    ----------\n",
        "    tetrode_key : tuple\n",
        "        Unique key identifying the tetrode. Elements are\n",
        "        (animal_short_name, day, epoch, tetrode_number).\n",
        "    animals : dict of named-tuples\n",
        "        Dictionary containing information about the directory for each\n",
        "        animal. The key is the animal_short_name.\n",
        "    Returns\n",
        "    -------\n",
        "    filename : str\n",
        "        File path to tetrode file LFP\n",
        "    '''\n",
        "    \n",
        "    animal, day, epoch, tetrode_number = tetrode_key\n",
        "    filename = ('{animal.short_name}eeg{day:02d}-{epoch}-'\n",
        "                '{tetrode_number:02d}.mat').format(\n",
        "                    animal=animals[animal], day=day, epoch=epoch,\n",
        "                    tetrode_number=tetrode_number)\n",
        "    return filename\n",
        "\n",
        "\n",
        "def convert_neuron_epoch_to_dataframe_modified(tetrodes_in_epoch, animal, day,\n",
        "                                      epoch):\n",
        "    '''\n",
        "    Given an neuron data structure, return a cleaned up DataFrame\n",
        "    '''\n",
        "    DROP_COLUMNS = ['ripmodtag', 'thetamodtag', 'runripmodtag',\n",
        "                    'postsleepripmodtag', 'presleepripmodtag',\n",
        "                    'runthetamodtag', 'ripmodtag2', 'runripmodtag2',\n",
        "                    'postsleepripmodtag2', 'presleepripmodtag2',\n",
        "                    'ripmodtype', 'runripmodtype', 'postsleepripmodtype',\n",
        "                    'presleepripmodtype', 'FStag', 'ripmodtag3',\n",
        "                    'runripmodtag3', 'ripmodtype3', 'runripmodtype3',\n",
        "                    'tag', 'typetag', 'runripmodtype2',\n",
        "                    'tag2', 'ripmodtype2', 'descrip']\n",
        "\n",
        "    NEURON_INDEX = ['animal', 'day', 'epoch',\n",
        "                    'tetrode_number', 'neuron_number']\n",
        "\n",
        "    neuron_dict_list = [_add_to_dict(\n",
        "        _convert_to_dict_modified(neuron), tetrode_ind, neuron_ind)\n",
        "        for tetrode_ind, tetrode in enumerate(\n",
        "        tetrodes_in_epoch[0][0])\n",
        "        for neuron_ind, neuron in enumerate(tetrode[0])\n",
        "        #if neuron.size > 0\n",
        "    ]\n",
        "    try:\n",
        "        return (pd.DataFrame(neuron_dict_list)\n",
        "                  .drop(DROP_COLUMNS, axis=1, errors='ignore')\n",
        "                  .assign(animal=animal)\n",
        "                  .assign(day=day)\n",
        "                  .assign(epoch=epoch)\n",
        "                  .assign(neuron_id=_get_neuron_id)\n",
        "                # set index to identify rows\n",
        "                  .set_index(NEURON_INDEX)\n",
        "                  .sort_index())\n",
        "    except AttributeError:\n",
        "        logger.debug(f'Neuron info {animal}, {day}, {epoch} not processed')\n",
        "\n",
        "def _convert_to_dict_modified(struct_array):\n",
        "    try:\n",
        "        return {name: struct_array[name].item().item()\n",
        "                for name in struct_array.dtype.names\n",
        "                if struct_array[name].item().size == 1}\n",
        "    except TypeError:\n",
        "        return {}\n",
        "    #added in the AttributeError\n",
        "    except AttributeError:\n",
        "        return {}\n",
        "\n",
        "def get_spike_indicator_dataframe_modified(neuron_key, animals, time_function=default_time_functionNEW):\n",
        "    time = time_function()\n",
        "    spikes_df = get_spikes_dataframe(neuron_key, animals)\n",
        "    print(spikes_df.index_total_seconds)\n",
        "    print(time.index.total_seconds)\n",
        "    time_index = None\n",
        "    try:\n",
        "    \n",
        "        time_index = np.digitize(spikes_df.index.total_seconds(),\n",
        "                             time.index.total_seconds())\n",
        " \n",
        "        time_index[time_index >= len(time)] = len(time) -1\n",
        "    #the exception is for empty data\n",
        "    except AttributeError: \n",
        "        print('No spikes here; data is emtpy')\n",
        "    \n",
        "    #the following accounts for an empty time_index\n",
        "    if time_index is not None:\n",
        "      return (spikes_df.groupby(time.iloc[time_index]).sum().reindex(index=time, fill_value=0))\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def _convert_to_dict_modified(struct_array):\n",
        "    try:\n",
        "        return {name: struct_array[name].item().item()\n",
        "                for name in struct_array.dtype.names\n",
        "                if struct_array[name].item().size == 1}\n",
        "    except TypeError:\n",
        "        return {}\n",
        "    #added in the AttributeError\n",
        "    except AttributeError:\n",
        "        return {}\n",
        "\n",
        "def _get_neuron_id(dataframe):\n",
        "    '''Unique identifier string for a neuron'''\n",
        "    return (dataframe.animal + '_' +\n",
        "            dataframe.day.map('{:02d}'.format) + '_' +\n",
        "            dataframe.epoch.map('{:02}'.format) + '_' +\n",
        "            dataframe.tetrode_number.map('{:03}'.format) + '_' +\n",
        "            dataframe.neuron_number.map('{:03}'.format))\n",
        "\n",
        "def get_trial_time_modified_3(epoch_key, animals):\n",
        "    \"\"\"Time in the recording session in terms of the LFP.\n",
        "    This will return the LFP time of the first tetrode found (according to the\n",
        "    tetrode info). This is useful when there are slightly different timings\n",
        "    for the recordings and you need a common time.\n",
        "    Parameters\n",
        "    ----------\n",
        "    epoch_key : tuple\n",
        "        Unique key identifying a recording epoch with elements\n",
        "        (animal, day, epoch)\n",
        "    animals : dict of named-tuples\n",
        "        Dictionary containing information about the directory for each\n",
        "        animal. The key is the animal_short_name.\n",
        "    Returns\n",
        "    -------\n",
        "    time : pandas.Index\n",
        "    \"\"\"\n",
        "    tetrode_info = make_tetrode_dataframe_modified(animals, epoch_key=epoch_key)\n",
        "    for tetrode_key in tetrode_info.index:\n",
        "        tetrode_key = str(tetrode_key)\n",
        "        print(tetrode_key)\n",
        "        tetrode_key = ','.join(tetrode_key.split('_'))\n",
        "        print(tetrode_key)\n",
        "        lfp_df = get_LFP_dataframe_modified(tetrode_key, animals)\n",
        "        if lfp_df is not None:\n",
        "            break\n",
        "\n",
        "    return lfp_df.index.rename(\"time\")\n",
        "\n",
        "def get_tetrode_info_path_modified(animal):\n",
        "    '''Returns the Matlab tetrode info file name assuming it is in the\n",
        "    Raw Data directory.\n",
        "    Parameters\n",
        "    ----------\n",
        "    animal : namedtuple\n",
        "        First element is the directory where the animal's data is located.\n",
        "        The second element is the animal shortened name.\n",
        "    Returns\n",
        "    -------\n",
        "    filename : str\n",
        "        The path to the information about the tetrodes for a given animal.\n",
        "    '''\n",
        "    filename = '{animal}tetinfo'.format(animal=animal)\n",
        "    return filename\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_aRDfwfFULb"
      },
      "outputs": [],
      "source": [
        "#new functions\n",
        "\n",
        "#the following function sums the number of spikes over the different time_series (one per neuron, initially), to create one time-series array for the collective activity\n",
        "def sum_time_series_dict(time_series_dict):\n",
        "    \n",
        "    num_bins = max([len(x) for x in time_series_dict.values() if x is not None])\n",
        "    res = np.zeros(num_bins)\n",
        "    for arr in time_series_dict.values():\n",
        "        if arr is not None:\n",
        "            res[:len(arr)] += arr\n",
        "    return res\n",
        "\n",
        "#this function is used to subdivide the list of all the neuron-ids into more manageable chunks.\n",
        "def divide_list_of_strings(strings, n):\n",
        "    # calculate the target number of strings per sublist\n",
        "    target = len(strings) // n\n",
        "    # initialize the list of sublists\n",
        "    sublists = [[] for _ in range(n)]\n",
        "    # initialize the index of the current sublist\n",
        "    index = 0\n",
        "    # loop through the input strings and distribute them evenly among the sublists\n",
        "    for string in strings:\n",
        "        # add the current string to the current sublist\n",
        "        sublists[index].append(string)\n",
        "        # move to the next sublist if the current sublist is full\n",
        "        if len(sublists[index]) == target:\n",
        "            index += 1\n",
        "    # return the list of sublists\n",
        "    return sublists\n",
        "\n",
        "\n",
        "#generate dict of keys of neurons with time series\n",
        "def generate_spike_indicator_dict(neuron_key_list, animals):\n",
        "    spike_indicator_dict = {}\n",
        "    for neuron_key_str in neuron_key_list:\n",
        "        \n",
        "        animal_short_name, day_number, epoch_number, tetrode_number, neuron_number = neuron_key_str.split(\"_\")\n",
        "        neuron_key = (animal_short_name, int(day_number), int(epoch_number), int(tetrode_number), int(neuron_number))\n",
        "        try:\n",
        "            spike_indicator_array = get_spike_indicator_dataframe_modified(neuron_key, animals).values\n",
        "        except AttributeError:\n",
        "            spike_indicator_array = None\n",
        "            print(f\"No spike indicator data for neuron: {neuron_key}\")\n",
        "        spike_indicator_dict[neuron_key] = spike_indicator_array\n",
        "    return spike_indicator_dict\n",
        "\n",
        "\n",
        "def split_neuron_dataframe_informationally(df, split_cols):\n",
        "    '''Splits a DataFrame into multiple DataFrames based on specified\n",
        "    column values.\n",
        "    Parameters\n",
        "    ----------\n",
        "    df : pandas.DataFrame\n",
        "        The DataFrame to be split.\n",
        "    split_cols : list of str\n",
        "        The names of the columns to use for splitting the DataFrame.\n",
        "    Returns\n",
        "    -------\n",
        "    dfs : dict\n",
        "        A dictionary containing the split DataFrames. The keys are tuples\n",
        "        containing the unique combinations of the specified column values.\n",
        "    '''\n",
        "    dfs = {}\n",
        "    for idx, group in df.groupby(split_cols):\n",
        "        dfs[idx] = group.copy()\n",
        "    return dfs\n",
        "\n",
        "  \n",
        "def apply_input_handler_to_split_dataframes(dfs):\n",
        "    '''\n",
        "    Applies mre.input_handler() to each DataFrame in the input dictionary.\n",
        "    Parameters\n",
        "    ----------\n",
        "    dfs : dict\n",
        "        A dictionary containing split DataFrames.\n",
        "    Returns\n",
        "    -------\n",
        "    output : dict\n",
        "        A dictionary containing the split DataFrames, with mre.input_handler()\n",
        "        applied to each DataFrame.\n",
        "    '''\n",
        "    output = {}\n",
        "    for key, df in dfs.items():\n",
        "        output[key] = mre.input_handler(df)\n",
        "    return output\n",
        "\n",
        "def get_neuron_ids_only(dfs):\n",
        "    \"\"\"\n",
        "    Takes a dictionary of pandas dataframes and returns a list of lists,\n",
        "    where each sublist contains the neuron ids for a unique area/subarea\n",
        "    combination.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    dfs : dict\n",
        "        Dictionary of pandas dataframes.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    neuron_ids : list of lists\n",
        "        List of lists, where each sublist contains the neuron ids for a unique\n",
        "        area/subarea combination.\n",
        "    \"\"\"\n",
        "    neuron_ids = []\n",
        "    for area_subarea in dfs.keys():\n",
        "        df = dfs[area_subarea]\n",
        "        area, subarea = area_subarea\n",
        "        neuron_ids.append([area, subarea, df['neuron_id'].tolist()])\n",
        "    return neuron_ids"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QelCLP9_L8Knd2_CcAbQMpFJESu3jceE",
      "authorship_tag": "ABX9TyOWrkedLut2T/jAU3Igc6uO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}