{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4eb4c-6f03-479c-87b0-c4d2e896a58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf0a497-0650-41cf-9624-ec16a1af03f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Loaded mrestimator v0.1.8, writing to /tmp/mre_dekorvyb/\n",
      "INFO     Using numba for parallelizable functions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for animal: gov, area: CA1\n",
      "animal_full_names: [Animal(short_name='/local2/Jan/Egypt/Egypt', directory='egy'), Animal(short_name='/local2/Jan/Remy/Remy', directory='remy'), Animal(short_name='/local2/Jan/Government/Government', directory='gov'), Animal(short_name='/local2/Jan/Frank/Frank', directory='fra')]\n",
      "animal: Animal(short_name='/local2/Jan/Egypt/Egypt', directory='egy')\n",
      "task_files: ['/local2/Jan/Egypt/Egypt/egytask02.mat', '/local2/Jan/Egypt/Egypt/egytask06.mat', '/local2/Jan/Egypt/Egypt/egytask07.mat', '/local2/Jan/Egypt/Egypt/egytask04.mat', '/local2/Jan/Egypt/Egypt/egytask05.mat', '/local2/Jan/Egypt/Egypt/egytask11.mat', '/local2/Jan/Egypt/Egypt/egytask09.mat', '/local2/Jan/Egypt/Egypt/egytask08.mat', '/local2/Jan/Egypt/Egypt/egytask10.mat', '/local2/Jan/Egypt/Egypt/egytask01.mat', '/local2/Jan/Egypt/Egypt/egytask03.mat']\n",
      "animal: Animal(short_name='/local2/Jan/Remy/Remy', directory='remy')\n",
      "task_files: ['/local2/Jan/Remy/Remy/remytask36.mat', '/local2/Jan/Remy/Remy/remytask37.mat', '/local2/Jan/Remy/Remy/remytask35.mat']\n",
      "animal: Animal(short_name='/local2/Jan/Government/Government', directory='gov')\n",
      "task_files: ['/local2/Jan/Government/Government/govtask01.mat', '/local2/Jan/Government/Government/govtask08.mat', '/local2/Jan/Government/Government/govtask11.mat', '/local2/Jan/Government/Government/govtask12.mat', '/local2/Jan/Government/Government/govtask05.mat', '/local2/Jan/Government/Government/govtask07.mat', '/local2/Jan/Government/Government/govtask02.mat', '/local2/Jan/Government/Government/govtask04.mat', '/local2/Jan/Government/Government/govtask09.mat', '/local2/Jan/Government/Government/govtask06.mat', '/local2/Jan/Government/Government/govtask10.mat', '/local2/Jan/Government/Government/govtask13.mat', '/local2/Jan/Government/Government/govtask03.mat']\n",
      "animal: Animal(short_name='/local2/Jan/Frank/Frank', directory='fra')\n",
      "task_files: ['/local2/Jan/Frank/Frank/fratask02.mat', '/local2/Jan/Frank/Frank/fratask09.mat', '/local2/Jan/Frank/Frank/fratask04.mat', '/local2/Jan/Frank/Frank/fratask10.mat', '/local2/Jan/Frank/Frank/fratask05.mat', '/local2/Jan/Frank/Frank/fratask07.mat', '/local2/Jan/Frank/Frank/fratask08.mat', '/local2/Jan/Frank/Frank/fratask03.mat', '/local2/Jan/Frank/Frank/fratask06.mat', '/local2/Jan/Frank/Frank/fratask11.mat', '/local2/Jan/Frank/Frank/fratask12.mat']\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes03.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 3, 6, 19, 1)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes03.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 3, 6, 19, 1)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes03.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 3, 6, 19, 1)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes04.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 4, 6, 14, 3)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes04.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 4, 6, 14, 3)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes04.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 4, 6, 14, 3)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 6, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 6, 21, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 6, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 6, 21, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 6, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 6, 21, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 2, 14, 1)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 2, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 2, 14, 1)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 2, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 2, 14, 1)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 2, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 4, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 4, 21, 1)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 4, 21, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 4, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 4, 21, 1)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 4, 21, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 4, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 4, 21, 1)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 4, 21, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes07.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 7, 9, 12, 4)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes08.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 8, 9, 12, 6)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes08.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 8, 6, 12, 6)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes08.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 8, 6, 12, 6)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes08.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 8, 6, 12, 6)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 3, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 3, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "No spike indicator data for neuron: ('gov', 5, 3, 14, 2)\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "animal_full_names: [Animal(short_name='/local2/Jan/Egypt/Egypt', directory='egy'), Animal(short_name='/local2/Jan/Remy/Remy', directory='remy'), Animal(short_name='/local2/Jan/Government/Government', directory='gov'), Animal(short_name='/local2/Jan/Frank/Frank', directory='fra')]\n",
      "animal: Animal(short_name='/local2/Jan/Egypt/Egypt', directory='egy')\n",
      "task_files: ['/local2/Jan/Egypt/Egypt/egytask02.mat', '/local2/Jan/Egypt/Egypt/egytask06.mat', '/local2/Jan/Egypt/Egypt/egytask07.mat', '/local2/Jan/Egypt/Egypt/egytask04.mat', '/local2/Jan/Egypt/Egypt/egytask05.mat', '/local2/Jan/Egypt/Egypt/egytask11.mat', '/local2/Jan/Egypt/Egypt/egytask09.mat', '/local2/Jan/Egypt/Egypt/egytask08.mat', '/local2/Jan/Egypt/Egypt/egytask10.mat', '/local2/Jan/Egypt/Egypt/egytask01.mat', '/local2/Jan/Egypt/Egypt/egytask03.mat']\n",
      "animal: Animal(short_name='/local2/Jan/Remy/Remy', directory='remy')\n",
      "task_files: ['/local2/Jan/Remy/Remy/remytask36.mat', '/local2/Jan/Remy/Remy/remytask37.mat', '/local2/Jan/Remy/Remy/remytask35.mat']\n",
      "animal: Animal(short_name='/local2/Jan/Government/Government', directory='gov')\n",
      "task_files: ['/local2/Jan/Government/Government/govtask01.mat', '/local2/Jan/Government/Government/govtask08.mat', '/local2/Jan/Government/Government/govtask11.mat', '/local2/Jan/Government/Government/govtask12.mat', '/local2/Jan/Government/Government/govtask05.mat', '/local2/Jan/Government/Government/govtask07.mat', '/local2/Jan/Government/Government/govtask02.mat', '/local2/Jan/Government/Government/govtask04.mat', '/local2/Jan/Government/Government/govtask09.mat', '/local2/Jan/Government/Government/govtask06.mat', '/local2/Jan/Government/Government/govtask10.mat', '/local2/Jan/Government/Government/govtask13.mat', '/local2/Jan/Government/Government/govtask03.mat']\n",
      "animal: Animal(short_name='/local2/Jan/Frank/Frank', directory='fra')\n",
      "task_files: ['/local2/Jan/Frank/Frank/fratask02.mat', '/local2/Jan/Frank/Frank/fratask09.mat', '/local2/Jan/Frank/Frank/fratask04.mat', '/local2/Jan/Frank/Frank/fratask10.mat', '/local2/Jan/Frank/Frank/fratask05.mat', '/local2/Jan/Frank/Frank/fratask07.mat', '/local2/Jan/Frank/Frank/fratask08.mat', '/local2/Jan/Frank/Frank/fratask03.mat', '/local2/Jan/Frank/Frank/fratask06.mat', '/local2/Jan/Frank/Frank/fratask11.mat', '/local2/Jan/Frank/Frank/fratask12.mat']\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes03.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes03.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes03.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes04.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes04.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes04.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes07.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes08.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes08.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes08.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes08.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/govspikes05.mat\n",
      "No spikes here; data is emtpy\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-01.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-02.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-03.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-04.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-05.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-06.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-07.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-08.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-09.mat\n",
      "Failed to load file: /local2/Jan/Government/Government/EEG/goveeg06-9-10.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wake': {3: {2: time\n",
      "0 days 01:14:39.983800       0.0\n",
      "0 days 01:14:39.984466666    0.0\n",
      "0 days 01:14:39.985133333    0.0\n",
      "0 days 01:14:39.985799999    0.0\n",
      "0 days 01:14:39.986466666    0.0\n",
      "                            ... \n",
      "0 days 01:30:00.015100       0.0\n",
      "0 days 01:30:00.015766667    0.0\n",
      "0 days 01:30:00.016433333    0.0\n",
      "0 days 01:30:00.017100       0.0\n",
      "0 days 01:30:00.017766667    0.0\n",
      "Length: 1380052, dtype: float64, 4: time\n",
      "0 days 01:49:49.985100       0.0\n",
      "0 days 01:49:49.985766666    0.0\n",
      "0 days 01:49:49.986433333    0.0\n",
      "0 days 01:49:49.987100       0.0\n",
      "0 days 01:49:49.987766666    0.0\n",
      "                            ... \n",
      "0 days 02:04:30.015800       0.0\n",
      "0 days 02:04:30.016466666    0.0\n",
      "0 days 02:04:30.017133333    0.0\n",
      "0 days 02:04:30.017800       0.0\n",
      "0 days 02:04:30.018466667    0.0\n",
      "Length: 1320051, dtype: float64, 6: time\n",
      "0 days 02:21:09.997100       0.0\n",
      "0 days 02:21:09.997766666    0.0\n",
      "0 days 02:21:09.998433333    0.0\n",
      "0 days 02:21:09.999100       0.0\n",
      "0 days 02:21:09.999766666    0.0\n",
      "                            ... \n",
      "0 days 02:36:25.001800       0.0\n",
      "0 days 02:36:25.002466666    0.0\n",
      "0 days 02:36:25.003133333    0.0\n",
      "0 days 02:36:25.003800       0.0\n",
      "0 days 02:36:25.004466667    0.0\n",
      "Length: 1372512, dtype: float64, 8: time\n",
      "0 days 02:53:19.985800       0.0\n",
      "0 days 02:53:19.986466666    0.0\n",
      "0 days 02:53:19.987133333    0.0\n",
      "0 days 02:53:19.987800       0.0\n",
      "0 days 02:53:19.988466666    0.0\n",
      "                            ... \n",
      "0 days 03:09:00.007799999    0.0\n",
      "0 days 03:09:00.008466666    0.0\n",
      "0 days 03:09:00.009133332    0.0\n",
      "0 days 03:09:00.009799999    0.0\n",
      "0 days 03:09:00.010466666    0.0\n",
      "Length: 1410038, dtype: float64}, 4: {2: time\n",
      "0 days 01:43:44.984600       0.0\n",
      "0 days 01:43:44.985266666    0.0\n",
      "0 days 01:43:44.985933333    0.0\n",
      "0 days 01:43:44.986600       0.0\n",
      "0 days 01:43:44.987266666    0.0\n",
      "                            ... \n",
      "0 days 01:57:45.014600       0.0\n",
      "0 days 01:57:45.015266667    0.0\n",
      "0 days 01:57:45.015933333    0.0\n",
      "0 days 01:57:45.016600       0.0\n",
      "0 days 01:57:45.017266667    0.0\n",
      "Length: 1260050, dtype: float64, 4: time\n",
      "0 days 02:17:58.996600       0.0\n",
      "0 days 02:17:58.997266666    0.0\n",
      "0 days 02:17:58.997933333    0.0\n",
      "0 days 02:17:58.998599999    0.0\n",
      "0 days 02:17:58.999266666    0.0\n",
      "                            ... \n",
      "0 days 02:33:00.003900       0.0\n",
      "0 days 02:33:00.004566667    0.0\n",
      "0 days 02:33:00.005233333    0.0\n",
      "0 days 02:33:00.005900       0.0\n",
      "0 days 02:33:00.006566667    0.0\n",
      "Length: 1351516, dtype: float64, 6: time\n",
      "0 days 03:08:10.994600       0.0\n",
      "0 days 03:08:10.995266666    0.0\n",
      "0 days 03:08:10.995933333    0.0\n",
      "0 days 03:08:10.996599999    0.0\n",
      "0 days 03:08:10.997266666    0.0\n",
      "                            ... \n",
      "0 days 03:23:59.001200       0.0\n",
      "0 days 03:23:59.001866667    0.0\n",
      "0 days 03:23:59.002533333    0.0\n",
      "0 days 03:23:59.003200       0.0\n",
      "0 days 03:23:59.003866667    0.0\n",
      "Length: 1422015, dtype: float64, 8: time\n",
      "0 days 03:58:05.998600       0.0\n",
      "0 days 03:58:05.999266666    0.0\n",
      "0 days 03:58:05.999933333    0.0\n",
      "0 days 03:58:06.000599999    0.0\n",
      "0 days 03:58:06.001266666    0.0\n",
      "                            ... \n",
      "0 days 04:14:05.005899999    0.0\n",
      "0 days 04:14:05.006566666    0.0\n",
      "0 days 04:14:05.007233332    0.0\n",
      "0 days 04:14:05.007899999    0.0\n",
      "0 days 04:14:05.008566666    0.0\n",
      "Length: 1438516, dtype: float64, 10: {}}, 5: {8: time\n",
      "0 days 03:49:26.986600       0.0\n",
      "0 days 03:49:26.987266666    0.0\n",
      "0 days 03:49:26.987933333    0.0\n",
      "0 days 03:49:26.988600       0.0\n",
      "0 days 03:49:26.989266666    0.0\n",
      "                            ... \n",
      "0 days 04:05:48.014600       0.0\n",
      "0 days 04:05:48.015266667    0.0\n",
      "0 days 04:05:48.015933333    0.0\n",
      "0 days 04:05:48.016600       0.0\n",
      "0 days 04:05:48.017266667    0.0\n",
      "Length: 1471547, dtype: float64, 10: {}, 6: time\n",
      "0 days 03:07:32.996000       0.0\n",
      "0 days 03:07:32.996666666    0.0\n",
      "0 days 03:07:32.997333333    0.0\n",
      "0 days 03:07:32.998000       0.0\n",
      "0 days 03:07:32.998666666    0.0\n",
      "                            ... \n",
      "0 days 03:22:40.016000       0.0\n",
      "0 days 03:22:40.016666667    0.0\n",
      "0 days 03:22:40.017333333    0.0\n",
      "0 days 03:22:40.018000       0.0\n",
      "0 days 03:22:40.018666667    0.0\n",
      "Length: 1360535, dtype: float64, 2: time\n",
      "0 days 01:35:54.982600       0.0\n",
      "0 days 01:35:54.983266666    0.0\n",
      "0 days 01:35:54.983933333    0.0\n",
      "0 days 01:35:54.984600       0.0\n",
      "0 days 01:35:54.985266666    0.0\n",
      "                            ... \n",
      "0 days 01:50:55.004000       0.0\n",
      "0 days 01:50:55.004666666    0.0\n",
      "0 days 01:50:55.005333333    0.0\n",
      "0 days 01:50:55.006000       0.0\n",
      "0 days 01:50:55.006666667    0.0\n",
      "Length: 1350037, dtype: float64, 4: time\n",
      "0 days 02:22:38.992600       0.0\n",
      "0 days 02:22:38.993266666    0.0\n",
      "0 days 02:22:38.993933333    0.0\n",
      "0 days 02:22:38.994600       0.0\n",
      "0 days 02:22:38.995266666    0.0\n",
      "                            ... \n",
      "0 days 02:37:41.005300       0.0\n",
      "0 days 02:37:41.005966666    0.0\n",
      "0 days 02:37:41.006633333    0.0\n",
      "0 days 02:37:41.007300       0.0\n",
      "0 days 02:37:41.007966667    0.0\n",
      "Length: 1353024, dtype: float64}, 6: {10: {}, 2: time\n",
      "0 days 01:12:07.985900       0.0\n",
      "0 days 01:12:07.986566666    0.0\n",
      "0 days 01:12:07.987233333    0.0\n",
      "0 days 01:12:07.987900       0.0\n",
      "0 days 01:12:07.988566666    0.0\n",
      "                            ... \n",
      "0 days 01:27:07.001899999    0.0\n",
      "0 days 01:27:07.002566666    0.0\n",
      "0 days 01:27:07.003233332    0.0\n",
      "0 days 01:27:07.003899999    0.0\n",
      "0 days 01:27:07.004566666    0.0\n",
      "Length: 1348529, dtype: float64, 4: time\n",
      "0 days 01:47:06.986600       0.0\n",
      "0 days 01:47:06.987266666    0.0\n",
      "0 days 01:47:06.987933333    0.0\n",
      "0 days 01:47:06.988599999    0.0\n",
      "0 days 01:47:06.989266666    0.0\n",
      "                            ... \n",
      "0 days 02:02:04.997200       0.0\n",
      "0 days 02:02:04.997866667    0.0\n",
      "0 days 02:02:04.998533333    0.0\n",
      "0 days 02:02:04.999200       0.0\n",
      "0 days 02:02:04.999866667    0.0\n",
      "Length: 1347021, dtype: float64}, 7: {9: time\n",
      "0 days 04:14:05.992500       0.0\n",
      "0 days 04:14:05.993166666    0.0\n",
      "0 days 04:14:05.993833333    0.0\n",
      "0 days 04:14:05.994500       0.0\n",
      "0 days 04:14:05.995166666    0.0\n",
      "                            ... \n",
      "0 days 04:30:06.005200       0.0\n",
      "0 days 04:30:06.005866666    0.0\n",
      "0 days 04:30:06.006533333    0.0\n",
      "0 days 04:30:06.007200       0.0\n",
      "0 days 04:30:06.007866667    0.0\n",
      "Length: 1440024, dtype: float64, 11: {}, 13: {}, 6: time\n",
      "0 days 03:08:15.999200       0.0\n",
      "0 days 03:08:15.999866666    0.0\n",
      "0 days 03:08:16.000533333    0.0\n",
      "0 days 03:08:16.001199999    0.0\n",
      "0 days 03:08:16.001866666    0.0\n",
      "                            ... \n",
      "0 days 03:23:26.015800001    0.0\n",
      "0 days 03:23:26.016466668    0.0\n",
      "0 days 03:23:26.017133334    0.0\n",
      "0 days 03:23:26.017800001    0.0\n",
      "0 days 03:23:26.018466668    0.0\n",
      "Length: 1365030, dtype: float64, 2: time\n",
      "0 days 01:49:17.998500       0.0\n",
      "0 days 01:49:17.999166666    0.0\n",
      "0 days 01:49:17.999833333    0.0\n",
      "0 days 01:49:18.000499999    0.0\n",
      "0 days 01:49:18.001166666    0.0\n",
      "                            ... \n",
      "0 days 02:04:19.005800       0.0\n",
      "0 days 02:04:19.006466667    0.0\n",
      "0 days 02:04:19.007133333    0.0\n",
      "0 days 02:04:19.007800       0.0\n",
      "0 days 02:04:19.008466667    0.0\n",
      "Length: 1351516, dtype: float64, 4: time\n",
      "0 days 02:28:04.997200       0.0\n",
      "0 days 02:28:04.997866666    0.0\n",
      "0 days 02:28:04.998533333    0.0\n",
      "0 days 02:28:04.999199999    0.0\n",
      "0 days 02:28:04.999866666    0.0\n",
      "                            ... \n",
      "0 days 02:43:35.004500       0.0\n",
      "0 days 02:43:35.005166667    0.0\n",
      "0 days 02:43:35.005833333    0.0\n",
      "0 days 02:43:35.006500       0.0\n",
      "0 days 02:43:35.007166667    0.0\n",
      "Length: 1395016, dtype: float64}, 8: {9: time\n",
      "0 days 04:17:22.991100       0.0\n",
      "0 days 04:17:22.991766666    0.0\n",
      "0 days 04:17:22.992433333    0.0\n",
      "0 days 04:17:22.993099999    0.0\n",
      "0 days 04:17:22.993766666    0.0\n",
      "                            ... \n",
      "0 days 04:32:23.012399999    0.0\n",
      "0 days 04:32:23.013066666    0.0\n",
      "0 days 04:32:23.013733332    0.0\n",
      "0 days 04:32:23.014399999    0.0\n",
      "0 days 04:32:23.015066666    0.0\n",
      "Length: 1350037, dtype: float64, 11: {}, 13: {}, 6: time\n",
      "0 days 03:21:59.997100       0.0\n",
      "0 days 03:21:59.997766666    0.0\n",
      "0 days 03:21:59.998433333    0.0\n",
      "0 days 03:21:59.999100       0.0\n",
      "0 days 03:21:59.999766666    0.0\n",
      "                            ... \n",
      "0 days 03:37:06.011800001    0.0\n",
      "0 days 03:37:06.012466667    0.0\n",
      "0 days 03:37:06.013133334    0.0\n",
      "0 days 03:37:06.013800001    0.0\n",
      "0 days 03:37:06.014466668    0.0\n",
      "Length: 1359027, dtype: float64, 2: time\n",
      "0 days 02:03:02.982400       0.0\n",
      "0 days 02:03:02.983066666    0.0\n",
      "0 days 02:03:02.983733333    0.0\n",
      "0 days 02:03:02.984400       0.0\n",
      "0 days 02:03:02.985066666    0.0\n",
      "                            ... \n",
      "0 days 02:19:28.998399999    0.0\n",
      "0 days 02:19:28.999066666    0.0\n",
      "0 days 02:19:28.999733332    0.0\n",
      "0 days 02:19:29.000399999    0.0\n",
      "0 days 02:19:29.001066666    0.0\n",
      "Length: 1479029, dtype: float64, 4: time\n",
      "0 days 02:42:41.987800       0.0\n",
      "0 days 02:42:41.988466666    0.0\n",
      "0 days 02:42:41.989133333    0.0\n",
      "0 days 02:42:41.989800       0.0\n",
      "0 days 02:42:41.990466666    0.0\n",
      "                            ... \n",
      "0 days 02:58:10.003800       0.0\n",
      "0 days 02:58:10.004466667    0.0\n",
      "0 days 02:58:10.005133333    0.0\n",
      "0 days 02:58:10.005800       0.0\n",
      "0 days 02:58:10.006466667    0.0\n",
      "Length: 1392029, dtype: float64}, 9: {10: {}, 12: {}, 2: time\n",
      "0 days 01:50:29.999500       0.0\n",
      "0 days 01:50:30.000166666    0.0\n",
      "0 days 01:50:30.000833333    0.0\n",
      "0 days 01:50:30.001500       0.0\n",
      "0 days 01:50:30.002166666    0.0\n",
      "                            ... \n",
      "0 days 02:05:54.999500       0.0\n",
      "0 days 02:05:55.000166667    0.0\n",
      "0 days 02:05:55.000833333    0.0\n",
      "0 days 02:05:55.001500       0.0\n",
      "0 days 02:05:55.002166667    0.0\n",
      "Length: 1387505, dtype: float64}, 10: {10: {}, 12: {}, 6: {}, 2: {}, 4: {}}, 11: {8: {}, 10: {}, 6: {}, 2: {}, 4: {}}, 12: {8: {}, 10: {}, 12: {}, 6: {}, 2: {}, 4: {}}, 13: {8: {}, 6: {}, 2: {}, 4: {}}}, 'sleep': {2: {1: time\n",
      "0 days 02:29:34.999800       0.0\n",
      "0 days 02:29:35.000466666    0.0\n",
      "0 days 02:29:35.001133333    0.0\n",
      "0 days 02:29:35.001799999    0.0\n",
      "0 days 02:29:35.002466666    0.0\n",
      "                            ... \n",
      "0 days 02:46:00.010400       0.0\n",
      "0 days 02:46:00.011066667    0.0\n",
      "0 days 02:46:00.011733333    0.0\n",
      "0 days 02:46:00.012400       0.0\n",
      "0 days 02:46:00.013066667    0.0\n",
      "Length: 1477521, dtype: float64}, 3: {1: time\n",
      "0 days 00:56:59.995100       0.0\n",
      "0 days 00:56:59.995766666    0.0\n",
      "0 days 00:56:59.996433333    0.0\n",
      "0 days 00:56:59.997100       0.0\n",
      "0 days 00:56:59.997766666    0.0\n",
      "                            ... \n",
      "0 days 01:13:45.015800       0.0\n",
      "0 days 01:13:45.016466666    0.0\n",
      "0 days 01:13:45.017133333    0.0\n",
      "0 days 01:13:45.017800       0.0\n",
      "0 days 01:13:45.018466667    0.0\n",
      "Length: 1507536, dtype: float64, 3: time\n",
      "0 days 01:30:44.987800       0.0\n",
      "0 days 01:30:44.988466666    0.0\n",
      "0 days 01:30:44.989133333    0.0\n",
      "0 days 01:30:44.989800       0.0\n",
      "0 days 01:30:44.990466666    0.0\n",
      "                            ... \n",
      "0 days 01:48:50.009799999    0.0\n",
      "0 days 01:48:50.010466666    0.0\n",
      "0 days 01:48:50.011133332    0.0\n",
      "0 days 01:48:50.011799999    0.0\n",
      "0 days 01:48:50.012466666    0.0\n",
      "Length: 1627538, dtype: float64, 5: time\n",
      "0 days 02:05:14.988400       0.0\n",
      "0 days 02:05:14.989066666    0.0\n",
      "0 days 02:05:14.989733333    0.0\n",
      "0 days 02:05:14.990400       0.0\n",
      "0 days 02:05:14.991066666    0.0\n",
      "                            ... \n",
      "0 days 02:20:30.012400       0.0\n",
      "0 days 02:20:30.013066667    0.0\n",
      "0 days 02:20:30.013733333    0.0\n",
      "0 days 02:20:30.014400       0.0\n",
      "0 days 02:20:30.015066667    0.0\n",
      "Length: 1372541, dtype: float64, 7: time\n",
      "0 days 02:37:09.993800       0.0\n",
      "0 days 02:37:09.994466666    0.0\n",
      "0 days 02:37:09.995133333    0.0\n",
      "0 days 02:37:09.995799999    0.0\n",
      "0 days 02:37:09.996466666    0.0\n",
      "                            ... \n",
      "0 days 02:52:10.015100       0.0\n",
      "0 days 02:52:10.015766667    0.0\n",
      "0 days 02:52:10.016433333    0.0\n",
      "0 days 02:52:10.017100       0.0\n",
      "0 days 02:52:10.017766667    0.0\n",
      "Length: 1350037, dtype: float64, 9: time\n",
      "0 days 03:09:54.995100       0.0\n",
      "0 days 03:09:54.995766666    0.0\n",
      "0 days 03:09:54.996433333    0.0\n",
      "0 days 03:09:54.997099999    0.0\n",
      "0 days 03:09:54.997766666    0.0\n",
      "                            ... \n",
      "0 days 03:25:50.000400       0.0\n",
      "0 days 03:25:50.001066667    0.0\n",
      "0 days 03:25:50.001733333    0.0\n",
      "0 days 03:25:50.002400       0.0\n",
      "0 days 03:25:50.003066667    0.0\n",
      "Length: 1432513, dtype: float64}, 4: {1: time\n",
      "0 days 01:25:14.999900       0.0\n",
      "0 days 01:25:15.000566666    0.0\n",
      "0 days 01:25:15.001233333    0.0\n",
      "0 days 01:25:15.001900       0.0\n",
      "0 days 01:25:15.002566666    0.0\n",
      "                            ... \n",
      "0 days 01:41:00.009900       0.0\n",
      "0 days 01:41:00.010566667    0.0\n",
      "0 days 01:41:00.011233333    0.0\n",
      "0 days 01:41:00.011900       0.0\n",
      "0 days 01:41:00.012566667    0.0\n",
      "Length: 1417520, dtype: float64, 3: time\n",
      "0 days 01:58:49.997200       0.0\n",
      "0 days 01:58:49.997866666    0.0\n",
      "0 days 01:58:49.998533333    0.0\n",
      "0 days 01:58:49.999200       0.0\n",
      "0 days 01:58:49.999866666    0.0\n",
      "                            ... \n",
      "0 days 02:16:05.003900       0.0\n",
      "0 days 02:16:05.004566666    0.0\n",
      "0 days 02:16:05.005233333    0.0\n",
      "0 days 02:16:05.005900       0.0\n",
      "0 days 02:16:05.006566667    0.0\n",
      "Length: 1552515, dtype: float64, 5: time\n",
      "0 days 02:34:34.991900       0.0\n",
      "0 days 02:34:34.992566666    0.0\n",
      "0 days 02:34:34.993233333    0.0\n",
      "0 days 02:34:34.993900       0.0\n",
      "0 days 02:34:34.994566666    0.0\n",
      "                            ... \n",
      "0 days 02:57:50.004599999    0.0\n",
      "0 days 02:57:50.005266665    0.0\n",
      "0 days 02:57:50.005933332    0.0\n",
      "0 days 02:57:50.006599999    0.0\n",
      "0 days 02:57:50.007266666    0.0\n",
      "Length: 2092524, dtype: float64, 7: time\n",
      "0 days 03:31:14.990600       0.0\n",
      "0 days 03:31:14.991266666    0.0\n",
      "0 days 03:31:14.991933333    0.0\n",
      "0 days 03:31:14.992599999    0.0\n",
      "0 days 03:31:14.993266666    0.0\n",
      "                            ... \n",
      "0 days 03:52:30.001199998    0.0\n",
      "0 days 03:52:30.001866665    0.0\n",
      "0 days 03:52:30.002533331    0.0\n",
      "0 days 03:52:30.003199998    0.0\n",
      "0 days 03:52:30.003866665    0.0\n",
      "Length: 1912521, dtype: float64, 9: time\n",
      "0 days 04:15:44.981900       0.0\n",
      "0 days 04:15:44.982566666    0.0\n",
      "0 days 04:15:44.983233333    0.0\n",
      "0 days 04:15:44.983899999    0.0\n",
      "0 days 04:15:44.984566666    0.0\n",
      "                            ... \n",
      "0 days 04:31:55.009199999    0.0\n",
      "0 days 04:31:55.009866666    0.0\n",
      "0 days 04:31:55.010533332    0.0\n",
      "0 days 04:31:55.011199999    0.0\n",
      "0 days 04:31:55.011866666    0.0\n",
      "Length: 1455046, dtype: float64, 11: {}}, 5: {1: time\n",
      "0 days 01:09:34.985300       0.0\n",
      "0 days 01:09:34.985966666    0.0\n",
      "0 days 01:09:34.986633333    0.0\n",
      "0 days 01:09:34.987300       0.0\n",
      "0 days 01:09:34.987966666    0.0\n",
      "                            ... \n",
      "0 days 01:29:15.011300       0.0\n",
      "0 days 01:29:15.011966667    0.0\n",
      "0 days 01:29:15.012633333    0.0\n",
      "0 days 01:29:15.013300       0.0\n",
      "0 days 01:29:15.013966667    0.0\n",
      "Length: 1770044, dtype: float64, 3: time\n",
      "0 days 01:51:32.997300       0.0\n",
      "0 days 01:51:32.997966666    0.0\n",
      "0 days 01:51:32.998633333    0.0\n",
      "0 days 01:51:32.999300       0.0\n",
      "0 days 01:51:32.999966666    0.0\n",
      "                            ... \n",
      "0 days 02:18:00.009300001    0.0\n",
      "0 days 02:18:00.009966668    0.0\n",
      "0 days 02:18:00.010633334    0.0\n",
      "0 days 02:18:00.011300001    0.0\n",
      "0 days 02:18:00.011966668    0.0\n",
      "Length: 2380523, dtype: float64, 5: time\n",
      "0 days 02:38:25.997300       0.0\n",
      "0 days 02:38:25.997966666    0.0\n",
      "0 days 02:38:25.998633333    0.0\n",
      "0 days 02:38:25.999300       0.0\n",
      "0 days 02:38:25.999966666    0.0\n",
      "                            ... \n",
      "0 days 03:03:59.997300       0.0\n",
      "0 days 03:03:59.997966667    0.0\n",
      "0 days 03:03:59.998633333    0.0\n",
      "0 days 03:03:59.999300       0.0\n",
      "0 days 03:03:59.999966667    0.0\n",
      "Length: 2301005, dtype: float64, 7: time\n",
      "0 days 03:23:34.984000       0.0\n",
      "0 days 03:23:34.984666666    0.0\n",
      "0 days 03:23:34.985333333    0.0\n",
      "0 days 03:23:34.986000       0.0\n",
      "0 days 03:23:34.986666666    0.0\n",
      "                            ... \n",
      "0 days 03:46:30.006000       0.0\n",
      "0 days 03:46:30.006666667    0.0\n",
      "0 days 03:46:30.007333333    0.0\n",
      "0 days 03:46:30.008000       0.0\n",
      "0 days 03:46:30.008666667    0.0\n",
      "Length: 2062538, dtype: float64, 9: time\n",
      "0 days 04:06:39.986000       0.0\n",
      "0 days 04:06:39.986666666    0.0\n",
      "0 days 04:06:39.987333333    0.0\n",
      "0 days 04:06:39.987999999    0.0\n",
      "0 days 04:06:39.988666666    0.0\n",
      "                            ... \n",
      "0 days 04:27:45.001300       0.0\n",
      "0 days 04:27:45.001966667    0.0\n",
      "0 days 04:27:45.002633333    0.0\n",
      "0 days 04:27:45.003300       0.0\n",
      "0 days 04:27:45.003966667    0.0\n",
      "Length: 1897528, dtype: float64, 11: {}, 12: {}}, 6: {1: time\n",
      "0 days 00:50:01.989900       0.0\n",
      "0 days 00:50:01.990566666    0.0\n",
      "0 days 00:50:01.991233333    0.0\n",
      "0 days 00:50:01.991899999    0.0\n",
      "0 days 00:50:01.992566666    0.0\n",
      "                            ... \n",
      "0 days 01:08:29.999200       0.0\n",
      "0 days 01:08:29.999866667    0.0\n",
      "0 days 01:08:30.000533333    0.0\n",
      "0 days 01:08:30.001200       0.0\n",
      "0 days 01:08:30.001866667    0.0\n",
      "Length: 1662019, dtype: float64, 3: time\n",
      "0 days 01:28:05.991200       0.0\n",
      "0 days 01:28:05.991866666    0.0\n",
      "0 days 01:28:05.992533333    0.0\n",
      "0 days 01:28:05.993200       0.0\n",
      "0 days 01:28:05.993866666    0.0\n",
      "                            ... \n",
      "0 days 01:42:59.999900       0.0\n",
      "0 days 01:43:00.000566666    0.0\n",
      "0 days 01:43:00.001233333    0.0\n",
      "0 days 01:43:00.001900       0.0\n",
      "0 days 01:43:00.002566667    0.0\n",
      "Length: 1341018, dtype: float64, 5: time\n",
      "0 days 02:03:19.994600       0.0\n",
      "0 days 02:03:19.995266666    0.0\n",
      "0 days 02:03:19.995933333    0.0\n",
      "0 days 02:03:19.996599999    0.0\n",
      "0 days 02:03:19.997266666    0.0\n",
      "                            ... \n",
      "0 days 02:26:47.999199998    0.0\n",
      "0 days 02:26:47.999866665    0.0\n",
      "0 days 02:26:48.000533331    0.0\n",
      "0 days 02:26:48.001199998    0.0\n",
      "0 days 02:26:48.001866665    0.0\n",
      "Length: 2112012, dtype: float64, 9: time\n",
      "0 days 03:38:04.999900       0.0\n",
      "0 days 03:38:05.000566666    0.0\n",
      "0 days 03:38:05.001233333    0.0\n",
      "0 days 03:38:05.001900       0.0\n",
      "0 days 03:38:05.002566666    0.0\n",
      "                            ... \n",
      "0 days 03:53:38.003899998    0.0\n",
      "0 days 03:53:38.004566665    0.0\n",
      "0 days 03:53:38.005233331    0.0\n",
      "0 days 03:53:38.005899998    0.0\n",
      "0 days 03:53:38.006566665    0.0\n",
      "Length: 1399511, dtype: float64, 11: {}, 13: {}}, 7: {1: time\n",
      "0 days 01:26:19.995800       0.0\n",
      "0 days 01:26:19.996466666    0.0\n",
      "0 days 01:26:19.997133333    0.0\n",
      "0 days 01:26:19.997800       0.0\n",
      "0 days 01:26:19.998466666    0.0\n",
      "                            ... \n",
      "0 days 01:46:20.012500       0.0\n",
      "0 days 01:46:20.013166666    0.0\n",
      "0 days 01:46:20.013833333    0.0\n",
      "0 days 01:46:20.014500       0.0\n",
      "0 days 01:46:20.015166667    0.0\n",
      "Length: 1800030, dtype: float64, 3: time\n",
      "0 days 02:05:14.998500       0.0\n",
      "0 days 02:05:14.999166666    0.0\n",
      "0 days 02:05:14.999833333    0.0\n",
      "0 days 02:05:15.000500       0.0\n",
      "0 days 02:05:15.001166666    0.0\n",
      "                            ... \n",
      "0 days 02:25:29.998499999    0.0\n",
      "0 days 02:25:29.999166666    0.0\n",
      "0 days 02:25:29.999833332    0.0\n",
      "0 days 02:25:30.000499999    0.0\n",
      "0 days 02:25:30.001166666    0.0\n",
      "Length: 1822505, dtype: float64, 5: time\n",
      "0 days 02:44:37.995800       0.0\n",
      "0 days 02:44:37.996466666    0.0\n",
      "0 days 02:44:37.997133333    0.0\n",
      "0 days 02:44:37.997800       0.0\n",
      "0 days 02:44:37.998466666    0.0\n",
      "                            ... \n",
      "0 days 03:05:14.997199999    0.0\n",
      "0 days 03:05:14.997866665    0.0\n",
      "0 days 03:05:14.998533332    0.0\n",
      "0 days 03:05:14.999199999    0.0\n",
      "0 days 03:05:14.999866666    0.0\n",
      "Length: 1855507, dtype: float64, 7: time\n",
      "0 days 03:24:29.993200       0.0\n",
      "0 days 03:24:29.993866666    0.0\n",
      "0 days 03:24:29.994533333    0.0\n",
      "0 days 03:24:29.995200       0.0\n",
      "0 days 03:24:29.995866666    0.0\n",
      "                            ... \n",
      "0 days 03:39:00.009199998    0.0\n",
      "0 days 03:39:00.009866665    0.0\n",
      "0 days 03:39:00.010533331    0.0\n",
      "0 days 03:39:00.011199998    0.0\n",
      "0 days 03:39:00.011866665    0.0\n",
      "Length: 1305029, dtype: float64, 8: time\n",
      "0 days 03:39:34.986500       0.0\n",
      "0 days 03:39:34.987166666    0.0\n",
      "0 days 03:39:34.987833333    0.0\n",
      "0 days 03:39:34.988500       0.0\n",
      "0 days 03:39:34.989166666    0.0\n",
      "                            ... \n",
      "0 days 04:08:00.009200       0.0\n",
      "0 days 04:08:00.009866666    0.0\n",
      "0 days 04:08:00.010533333    0.0\n",
      "0 days 04:08:00.011200       0.0\n",
      "0 days 04:08:00.011866667    0.0\n",
      "Length: 2557539, dtype: float64, 10: {}, 12: {}}, 8: {1: time\n",
      "0 days 01:30:49.997100       0.0\n",
      "0 days 01:30:49.997766666    0.0\n",
      "0 days 01:30:49.998433333    0.0\n",
      "0 days 01:30:49.999099999    0.0\n",
      "0 days 01:30:49.999766666    0.0\n",
      "                            ... \n",
      "0 days 01:50:20.008400       0.0\n",
      "0 days 01:50:20.009066667    0.0\n",
      "0 days 01:50:20.009733333    0.0\n",
      "0 days 01:50:20.010400       0.0\n",
      "0 days 01:50:20.011066667    0.0\n",
      "Length: 1755022, dtype: float64, 3: time\n",
      "0 days 02:20:27.987800       0.0\n",
      "0 days 02:20:27.988466666    0.0\n",
      "0 days 02:20:27.989133333    0.0\n",
      "0 days 02:20:27.989800       0.0\n",
      "0 days 02:20:27.990466666    0.0\n",
      "                            ... \n",
      "0 days 02:40:00.009800       0.0\n",
      "0 days 02:40:00.010466667    0.0\n",
      "0 days 02:40:00.011133333    0.0\n",
      "0 days 02:40:00.011800       0.0\n",
      "0 days 02:40:00.012466667    0.0\n",
      "Length: 1758038, dtype: float64, 5: time\n",
      "0 days 02:59:14.986400       0.0\n",
      "0 days 02:59:14.987066666    0.0\n",
      "0 days 02:59:14.987733333    0.0\n",
      "0 days 02:59:14.988400       0.0\n",
      "0 days 02:59:14.989066666    0.0\n",
      "                            ... \n",
      "0 days 03:19:30.005800       0.0\n",
      "0 days 03:19:30.006466666    0.0\n",
      "0 days 03:19:30.007133333    0.0\n",
      "0 days 03:19:30.007800       0.0\n",
      "0 days 03:19:30.008466667    0.0\n",
      "Length: 1822534, dtype: float64, 7: time\n",
      "0 days 03:38:41.985800       0.0\n",
      "0 days 03:38:41.986466666    0.0\n",
      "0 days 03:38:41.987133333    0.0\n",
      "0 days 03:38:41.987799999    0.0\n",
      "0 days 03:38:41.988466666    0.0\n",
      "                            ... \n",
      "0 days 03:54:40.007100       0.0\n",
      "0 days 03:54:40.007766667    0.0\n",
      "0 days 03:54:40.008433333    0.0\n",
      "0 days 03:54:40.009100       0.0\n",
      "0 days 03:54:40.009766667    0.0\n",
      "Length: 1437037, dtype: float64, 8: time\n",
      "0 days 03:56:09.987800       0.0\n",
      "0 days 03:56:09.988466666    0.0\n",
      "0 days 03:56:09.989133333    0.0\n",
      "0 days 03:56:09.989799999    0.0\n",
      "0 days 03:56:09.990466666    0.0\n",
      "                            ... \n",
      "0 days 04:10:53.015099999    0.0\n",
      "0 days 04:10:53.015766666    0.0\n",
      "0 days 04:10:53.016433332    0.0\n",
      "0 days 04:10:53.017099999    0.0\n",
      "0 days 04:10:53.017766666    0.0\n",
      "Length: 1324546, dtype: float64, 10: {}, 12: {}, 15: {}}, 9: {1: time\n",
      "0 days 01:29:59.993500       0.0\n",
      "0 days 01:29:59.994166666    0.0\n",
      "0 days 01:29:59.994833333    0.0\n",
      "0 days 01:29:59.995500       0.0\n",
      "0 days 01:29:59.996166666    0.0\n",
      "                            ... \n",
      "0 days 01:46:59.997500       0.0\n",
      "0 days 01:46:59.998166667    0.0\n",
      "0 days 01:46:59.998833333    0.0\n",
      "0 days 01:46:59.999500       0.0\n",
      "0 days 01:47:00.000166667    0.0\n",
      "Length: 1530011, dtype: float64, 7: time\n",
      "0 days 03:47:13.982800       0.0\n",
      "0 days 03:47:13.983466666    0.0\n",
      "0 days 03:47:13.984133333    0.0\n",
      "0 days 03:47:13.984800       0.0\n",
      "0 days 03:47:13.985466666    0.0\n",
      "                            ... \n",
      "0 days 03:59:29.999500       0.0\n",
      "0 days 03:59:30.000166666    0.0\n",
      "0 days 03:59:30.000833333    0.0\n",
      "0 days 03:59:30.001500       0.0\n",
      "0 days 03:59:30.002166667    0.0\n",
      "Length: 1104030, dtype: float64, 9: time\n",
      "0 days 04:21:59.991500       0.0\n",
      "0 days 04:21:59.992166666    0.0\n",
      "0 days 04:21:59.992833333    0.0\n",
      "0 days 04:21:59.993500       0.0\n",
      "0 days 04:21:59.994166666    0.0\n",
      "                            ... \n",
      "0 days 04:34:30.005500001    0.0\n",
      "0 days 04:34:30.006166668    0.0\n",
      "0 days 04:34:30.006833334    0.0\n",
      "0 days 04:34:30.007500001    0.0\n",
      "0 days 04:34:30.008166668    0.0\n",
      "Length: 1125026, dtype: float64, 11: {}, 13: {}}, 10: {1: {}, 3: {}, 5: {}, 7: {}, 9: {}, 11: {}}, 11: {1: {}, 3: {}, 5: {}, 7: {}, 9: {}, 11: {}}, 12: {1: {}, 3: {}, 5: {}, 7: {}, 9: {}, 11: {}, 14: {}}, 13: {1: {}, 3: {}, 5: {}, 7: {}, 9: {}, 11: {}}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.97259, tau = 35.98ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000000 B=0.000015 C=-0.000015\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000001 B=0.000002 C=-0.000002\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000004 B=0.000009 C=-0.000009\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.96983, tau = 32.64ms, ssres = 0.24999\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000000 B=0.000427 C=-0.000439\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.96979, tau = 32.60ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000000 B=0.000006 C=-0.000006\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000004 B=0.000009 C=-0.000009\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.89585, tau = 9.09ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000000 B=0.000077 C=-0.000079\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "ERROR    Provided coefficients contain elements that are not finite. Fits would not converge.\n",
      "         One can use `np.isfinite(data.coefficients)` to find problematic elements.\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing for state: wake, day: 3, epoch; 2. Error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "ERROR    Provided coefficients contain elements that are not finite. Fits would not converge.\n",
      "         One can use `np.isfinite(data.coefficients)` to find problematic elements.\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing for state: wake, day: 3, epoch; 2. Error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000002 B=0.000005 C=-0.000005\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000001 B=0.000002 C=-0.000002\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99857, tau = 697.13ms, ssres = 0.20281\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000688 B=0.000873 C=-0.001899\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "ERROR    Provided coefficients contain elements that are not finite. Fits would not converge.\n",
      "         One can use `np.isfinite(data.coefficients)` to find problematic elements.\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing for state: wake, day: 3, epoch; 4. Error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "ERROR    Provided coefficients contain elements that are not finite. Fits would not converge.\n",
      "         One can use `np.isfinite(data.coefficients)` to find problematic elements.\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing for state: wake, day: 3, epoch; 4. Error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99944, tau = 1779.33ms, ssres = 0.24980\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "ERROR    Provided coefficients contain elements that are not finite. Fits would not converge.\n",
      "         One can use `np.isfinite(data.coefficients)` to find problematic elements.\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing for state: wake, day: 3, epoch; 4. Error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "ERROR    Provided coefficients contain elements that are not finite. Fits would not converge.\n",
      "         One can use `np.isfinite(data.coefficients)` to find problematic elements.\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing for state: wake, day: 3, epoch; 4. Error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.97030, tau = 33.17ms, ssres = 0.12499\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000000 B=0.000468 C=-0.000479\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99937, tau = 1579.25ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000001 B=0.000002 C=-0.000002\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.86228, tau = 6.75ms, ssres = 0.02669\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.040260 B=5.000000 C=-4.975103\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.97397, tau = 37.91ms, ssres = 0.14008\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.94963, tau = 19.35ms, ssres = 0.17192\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.175294 B=4.865631 C=-4.999999\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.98594, tau = 70.63ms, ssres = 0.21100\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.009761 B=-1.015109 C=1.058499\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.92523, tau = 12.87ms, ssres = 0.10188\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.89471, tau = 8.99ms, ssres = 0.27990\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.95954, tau = 24.21ms, ssres = 0.11766\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.022530 B=-0.055264 C=0.036781\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.92887, tau = 13.55ms, ssres = 0.13628\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000002 B=0.000005 C=-0.000005\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99192, tau = 123.27ms, ssres = 0.08908\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.005033 B=4.791326 C=-4.774411\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99951, tau = 2052.02ms, ssres = 0.34550\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.001968 B=0.010216 C=-0.011737\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "ERROR    Provided coefficients contain elements that are not finite. Fits would not converge.\n",
      "         One can use `np.isfinite(data.coefficients)` to find problematic elements.\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing for state: wake, day: 3, epoch; 8. Error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.00000\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.000001 B=0.000002 C=-0.000002\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.97404, tau = 38.01ms, ssres = 0.43609\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "ERROR    Provided coefficients contain elements that are not finite. Fits would not converge.\n",
      "         One can use `np.isfinite(data.coefficients)` to find problematic elements.\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing for state: wake, day: 3, epoch; 8. Error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.45577\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.004148 B=0.032436 C=-0.047791\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.26005\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.008801 B=0.058521 C=-0.048738\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.14788\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.004187 B=0.072945 C=-0.057311\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.37594\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.007356 B=0.026475 C=-0.047101\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.89879, tau = 9.37ms, ssres = 0.19242\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.357504 B=-4.995812 C=4.665501\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99970, tau = 3293.81ms, ssres = 0.10395\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.008268 B=0.009472 C=-0.028154\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99934, tau = 1507.02ms, ssres = 0.11960\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99923, tau = 1295.80ms, ssres = 0.17320\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99934, tau = 1525.04ms, ssres = 0.13263\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99933, tau = 1487.43ms, ssres = 0.13635\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99897, tau = 970.28ms, ssres = 0.13515\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99892, tau = 924.09ms, ssres = 0.15942\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.015262 B=0.018709 C=-0.029947\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99896, tau = 960.81ms, ssres = 0.14316\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.014331 B=0.024338 C=-0.031290\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99910, tau = 1106.70ms, ssres = 0.14822\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99971, tau = 3462.25ms, ssres = 0.11263\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.008428 B=0.004756 C=0.010221\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99942, tau = 1717.29ms, ssres = 0.11624\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99939, tau = 1630.11ms, ssres = 0.12161\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.009391 B=0.025703 C=-0.032670\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99937, tau = 1579.79ms, ssres = 0.13811\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.013938 B=0.018438 C=-0.032898\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99917, tau = 1198.74ms, ssres = 0.13858\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99895, tau = 948.92ms, ssres = 0.12715\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99919, tau = 1241.62ms, ssres = 0.11206\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99923, tau = 1302.89ms, ssres = 0.11735\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.009558 B=0.014610 C=-0.030689\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99916, tau = 1192.04ms, ssres = 0.14111\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99901, tau = 1005.56ms, ssres = 0.14554\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99977, tau = 4368.78ms, ssres = 0.11220\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.004016 B=0.016383 C=-0.028716\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99979, tau = 4874.48ms, ssres = 0.11612\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.003824 B=0.015486 C=-0.023363\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 4950.76ms, ssres = 0.10853\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.003684 B=0.019382 C=-0.023038\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99936, tau = 1553.63ms, ssres = 0.12014\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.004402 B=0.010289 C=-0.019399\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99943, tau = 1753.30ms, ssres = 0.10477\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.004310 B=0.007263 C=-0.018805\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.11635\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.003468 B=0.012633 C=-0.018931\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99947, tau = 1887.59ms, ssres = 0.11923\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.003509 B=0.011728 C=-0.017895\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99853, tau = 679.42ms, ssres = 0.12223\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.003448 B=-0.060689 C=0.027995\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99866, tau = 745.49ms, ssres = 0.10837\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.002374 B=0.013370 C=-0.021429\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99916, tau = 1185.83ms, ssres = 0.12443\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.005648 B=0.013557 C=-0.027810\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.20724\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.004638 B=0.051206 C=-0.041158\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.14824\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.006474 B=0.042147 C=-0.044463\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.14998\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.008789 B=0.060315 C=-0.051652\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99971, tau = 3445.25ms, ssres = 0.12735\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.002805 B=0.107707 C=-0.082654\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 4999.95ms, ssres = 0.11297\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.003170 B=0.091940 C=-0.062320\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99979, tau = 4840.03ms, ssres = 0.15848\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.008634 B=0.067048 C=-0.050710\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99956, tau = 2254.80ms, ssres = 0.12317\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.006219 B=0.054094 C=-0.046704\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99588, tau = 242.14ms, ssres = 0.12945\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.005855 B=0.079686 C=-0.056697\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99969, tau = 3265.54ms, ssres = 0.13632\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.006334 B=0.026015 C=-0.029829\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99980, tau = 5000.00ms, ssres = 0.10377\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.001770 B=0.139298 C=-0.100045\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99975, tau = 3993.08ms, ssres = 0.13886\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.003964 B=0.164017 C=-0.144785\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99978, tau = 4575.21ms, ssres = 0.14736\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.007211 B=5.000000 C=-4.972109\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99932, tau = 1466.54ms, ssres = 0.11746\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.007580 B=0.013517 C=-0.026838\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99899, tau = 991.51ms, ssres = 0.13319\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.010857 B=0.035614 C=-0.048630\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99914, tau = 1160.24ms, ssres = 0.12128\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99928, tau = 1395.91ms, ssres = 0.10880\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.010893 B=0.017103 C=-0.032609\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99917, tau = 1210.08ms, ssres = 0.11950\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.010967 B=0.028267 C=-0.041090\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99905, tau = 1057.06ms, ssres = 0.13740\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.008661 B=0.028974 C=-0.040688\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99888, tau = 894.12ms, ssres = 0.17336\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.012195 B=0.021960 C=-0.033264\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "INFO     Finished fitting the data to f_complex,\n",
      "         mre = 0.99915, tau = 1178.58ms, ssres = 0.16769\n",
      "WARNING  The amplitude of the exponential decay is smaller than corrections: A=0.012311 B=0.048857 C=-0.053911\n",
      "WARNING  You should provide an ndarray of shape(numtrials, datalength)\n",
      "         Continuing with one trial, reshaping your input\n",
      "INFO     coefficients() with 'trialseparated' method for 1 trials of length 135000.\n",
      "INFO     Bootstrapping needs at least 2 trials, skipping the resampling\n",
      "INFO     Given data is no CoefficientResult. Guessing format\n",
      "INFO     Bounded fit to $|A| e^{-k/\\tau} + B e^{-(k/\\tau_{osc})^\\gamma} \\cos(2 \\pi \\nu k) + C e^{-(k/\\tau_{gs})^2} + O$\n",
      "INFO     Fitting with 22 different start values\n",
      "                                            \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e2ebebc241dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0mlen_time_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m \u001b[0mintrinsic_time_scale_estimation_for_all_animals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimal_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_time_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e2ebebc241dc>\u001b[0m in \u001b[0;36mintrinsic_time_scale_estimation_for_all_animals\u001b[0;34m(animal_list, area_list, len_time_chunk)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;31m# Attempt to run the estimation function for each combination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing for animal: {animal}, area: {area}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mintrinsic_time_scale_estimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_time_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m#except Exception as e:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e2ebebc241dc>\u001b[0m in \u001b[0;36mintrinsic_time_scale_estimation\u001b[0;34m(animal, area, len_time_chunk)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m#print(neuron_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0msplitted_by_sec_spike_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spike_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen_time_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0mcompute_rk_and_tau_from_splitted_by_sec_spike_dict_trial_seperated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitted_by_sec_spike_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m'Done'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e2ebebc241dc>\u001b[0m in \u001b[0;36mcompute_rk_and_tau_from_splitted_by_sec_spike_dict_trial_seperated\u001b[0;34m(spike_dict, animal, area)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspike_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mday\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspike_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspike_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime_chunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspike_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mprocess_time_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspike_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manimal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error processing for state: {state}, day: {day}, epoch; {epoch}. Error: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e2ebebc241dc>\u001b[0m in \u001b[0;36mprocess_time_chunk\u001b[0;34m(spike_dict, state, day, epoch, animal, area, method, time_chunk)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mcoefficients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_coefficients_trial_seperated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0moutput_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# Extract additional data from the output_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-e2ebebc241dc>\u001b[0m in \u001b[0;36mfitting\u001b[0;34m(coefficients)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Define your fit function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfitting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefficients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f_complex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_time_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manimal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_chunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mrestimator/fit.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(data, fitfunc, steps, fitpars, fitbnds, maxfev, ignoreweights, numboot, quantiles, seed, desc, description)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfulpopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfulpcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssresmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m     fulpopt, fulpcov, ssresmin = fitloop(\n\u001b[0m\u001b[1;32m    645\u001b[0m         src.coefficients[stepinds], int(maxfev))\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/mrestimator/fit.py\u001b[0m in \u001b[0;36mfitloop\u001b[0;34m(ftcoefficients, ftmaxfev, fitlog)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                 popt, pcov = scipy.optimize.curve_fit(\n\u001b[0m\u001b[1;32m    618\u001b[0m                     \u001b[0mfitfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrcsteps\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftcoefficients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                     \u001b[0mp0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxfev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mftmaxfev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_minpack_py.py\u001b[0m in \u001b[0;36mcurve_fit\u001b[0;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_nfev'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maxfev'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m         res = least_squares(func, p0, jac=jac, bounds=bounds, method=method,\n\u001b[0m\u001b[1;32m    871\u001b[0m                             **kwargs)\n\u001b[1;32m    872\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_lsq/least_squares.py\u001b[0m in \u001b[0;36mleast_squares\u001b[0;34m(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         result = trf(fun_wrapped, jac_wrapped, x0, f0, J0, lb, ub, ftol, xtol,\n\u001b[0m\u001b[1;32m    939\u001b[0m                      \u001b[0mgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_nfev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_solver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                      tr_options.copy(), verbose)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_lsq/trf.py\u001b[0m in \u001b[0;36mtrf\u001b[0;34m(fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)\u001b[0m\n\u001b[1;32m    121\u001b[0m             loss_function, tr_solver, tr_options, verbose)\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         return trf_bounds(\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mftol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_nfev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             loss_function, tr_solver, tr_options, verbose)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_lsq/trf.py\u001b[0m in \u001b[0;36mtrf_bounds\u001b[0;34m(fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_for_robust_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mjac_scale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/optimize/_lsq/common.py\u001b[0m in \u001b[0;36mcompute_grad\u001b[0;34m(J, f)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmatvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # This is the analysis pipeline for the calculation of tau and branching factor of neural data from the hippocampus. \n",
    "# \n",
    "# The data are take from: https://datadryad.org/stash/dataset/doi:10.7272/Q61N7ZC3\n",
    "\n",
    "# ### Importing the branching factor/tau estimator\n",
    "# \n",
    "# For documentation regards the estimator see https://mrestimator.readthedocs.io/en/latest/doc/gettingstarted.html, Spitzner, F. P., Dehning, J., Wilting, J., Hagemann, A., P. Neto, J., Zierenberg, J., & Priesemann, V. (2021).\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import mrestimator as mre\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ### Importing relevant non-standard modules\n",
    "# All of which can be found on github https://github.com/JanBellingrath/Hippocampal_Neuron_Data_Processing\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import pipeline.utilities as u\n",
    "import criticality_analysis as can\n",
    "import compactifying_functions_up_to_date_version as compact\n",
    "\n",
    "\n",
    "# ### Defining each animal via its short name and its directory\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Animal = namedtuple('Animal', {'short_name', 'directory'})\n",
    "\n",
    "conley = Animal('/home/bellijjy/Conley.tar/Conley', 'con')\n",
    "dave = Animal('/home/bellijjy/Dave.tar/Dave/Dave', 'dav')\n",
    "chapati = Animal('/home/bellijjy/Chapati.tar/Chapati/Chapati', 'cha')\n",
    "corriander = Animal('/home/bellijjy/Corriander.tar/Corriander', 'Cor')\n",
    "dudley = Animal('/home/bellijjy/Dudley/dud', 'dud')\n",
    "bond = Animal('/home/bellijjy/Bond/bon', 'bon')\n",
    "frank = Animal('/local2/Jan/Frank/Frank', 'fra')\n",
    "government = Animal('/local2/Jan/Government/Government/gov', 'fra')\n",
    "egypt = Animal('/local2/Jan/Egypt/Egypt/egy', 'egy')\n",
    "remy = Animal('/local2/Jan/Remy/Remy/remy', 'remy')\n",
    "five = Animal(\"/home/dekorvyb/Downloads/Fiv\", \"Fiv\")\n",
    "bon = Animal(\"/home/dekorvyb/Downloads/Bon\", \"bon\")\n",
    "\n",
    "\n",
    "animals = {'con': Animal('con','/home/bellijjy/Conley.tar/Conley'),\n",
    "           'Cor': Animal('Cor','/home/bellijjy/Corriander.tar/Corriander'),\n",
    "            'cha': Animal('cha','/home/bellijjy/Chapati.tar/Chapati/Chapati'),\n",
    "          'dav': Animal('dav','/home/bellijjy/Dave.tar/Dave/Dave'),\n",
    "           'dud': Animal('dud','/home/bellijjy/Dudley'),\n",
    "            #'bon' : Animal('bon', '/home/bellijjy/Bond'),\n",
    "              'fra' : Animal('fra', '/local2/Jan/Frank/Frank'),\n",
    "              'gov' : Animal('gov', '/local2/Jan/Government/Government'),\n",
    "            'egy' : Animal('egy', '/local2/Jan/Egypt/Egypt'), \n",
    "          'remy': Animal('remy', '/local2/Jan/Remy/Remy'),\n",
    "          \"Fiv\" : Animal(\"Fiv\", \"/home/dekorvyb/Downloads/Fiv\"),\n",
    "          \"bon\" : Animal(\"bon\", \"/home/dekorvyb/Downloads/Bon\")}\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import product\n",
    "\n",
    "# Define your coefficient function\n",
    "def get_coefficients_trial_seperated(spike_dict, state, day, epoch, time_chunk):\n",
    "    return mre.coefficients(spike_dict[state][day][epoch][time_chunk], dt=6.67, dtunit='ms', method = 'ts')\n",
    "\n",
    "#probably need to add padding below\n",
    "def get_coefficients_stationary_mean(spike_dict, state, day, epoch):\n",
    "    #extracting all values (in an array for each time_chunk) per epoch (per stat, day)\n",
    "    all_time_chunks = spike_dict[state][day][epoch].values()\n",
    "    # Assuming each time_chunk is a 1D array, combine them into a 2D array (num_trials, data_length)\n",
    "    combined_trials = np.stack(all_time_chunks)\n",
    "\n",
    "    # Calculate coefficients using the specified method for the combined trials\n",
    "    coefficients = mre.coefficients(combined_trials, dt=6.67, dtunit='ms', method= 'sm')\n",
    "    \n",
    "    return coefficients\n",
    "\n",
    "    \n",
    "# Define your fit function\n",
    "def fitting(coefficients):\n",
    "    return mre.fit(coefficients.coefficients, fitfunc='f_complex')\n",
    "\n",
    "def process_time_chunk(spike_dict, state, day, epoch, animal, area, method, time_chunk):\n",
    "    \n",
    "    if method == 'sm':\n",
    "        \n",
    "        all_time_chunks = spike_dict[state][day][epoch]\n",
    "\n",
    "        # Convert all time chunks into a serializable format\n",
    "        # Assuming each time chunk is already in a format that can be serialized (like a list or a numpy array)\n",
    "        original_data = {time_chunk: data.tolist() for time_chunk, data in all_time_chunks.items()}\n",
    "\n",
    "        # Serialize the data to JSON\n",
    "        original_data_json = json.dumps(original_data)\n",
    "        \n",
    "        #if sm, then you fit all time chunks within one epoch.\n",
    "        coefficients = get_coefficients_stationary_mean(spike_dict, state, day, epoch)\n",
    "        \n",
    "        #mre.fit in fitting automatically fits the array structure\n",
    "        output_handler = fitting(coefficients)\n",
    "\n",
    "        # Extract additional data from the output_handler\n",
    "        additional_data = {\n",
    "            'popt': output_handler.popt,\n",
    "            'ssres': output_handler.ssres,\n",
    "            #'fitfunc': output_handler.fitfunc,\n",
    "            'pcov': [],\n",
    "            'steps': output_handler.steps,\n",
    "            'dt': output_handler.dt,\n",
    "            'dtunit': output_handler.dtunit,\n",
    "            'quantiles': output_handler.quantiles,\n",
    "            'mrequantiles': output_handler.mrequantiles,\n",
    "            'tauquantiles': output_handler.tauquantiles,\n",
    "            'description': output_handler.description\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "            'animal': animal,\n",
    "            'area': area,\n",
    "            'state': state,\n",
    "            'day': day,\n",
    "            'epoch': epoch,\n",
    "            'original_data': original_data_json,\n",
    "            'tau': output_handler.tau,\n",
    "            'branching_factor': output_handler.mre,\n",
    "        }\n",
    "\n",
    "        # Merge the additional data into the main data dictionary\n",
    "        data.update(additional_data)\n",
    "\n",
    "        #Add covariance matrix after conversion\n",
    "        data['pcov'] = json.dumps(data['pcov'])\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame([data])\n",
    "\n",
    "        # Save individual time_chunk to disk\n",
    "        directory = '/home/bellijjy/criticality_january_sm/'\n",
    "        file_name = f'{directory}_{animal}_{area}_{state}_{day}_{epoch}_{time_chunk}.parquet'\n",
    "        df.to_parquet(file_name, index=True)\n",
    "        print('saved')\n",
    "        \n",
    "        #return df\n",
    "    \n",
    "    else: \n",
    "        \n",
    "        original_data = spike_dict[state][day][epoch][time_chunk]\n",
    "        original_data_json = original_data.to_json()\n",
    "        \n",
    "        coefficients = get_coefficients_trial_seperated(spike_dict, state, day, epoch, time_chunk)\n",
    "        output_handler = fitting(coefficients)\n",
    "\n",
    "        # Extract additional data from the output_handler\n",
    "        additional_data = {\n",
    "            'popt': output_handler.popt,\n",
    "            'ssres': output_handler.ssres,\n",
    "            #'fitfunc': output_handler.fitfunc,\n",
    "            'pcov': [],\n",
    "            'steps': output_handler.steps,\n",
    "            'dt': output_handler.dt,\n",
    "            'dtunit': output_handler.dtunit,\n",
    "            'quantiles': output_handler.quantiles,\n",
    "            'mrequantiles': output_handler.mrequantiles,\n",
    "            'tauquantiles': output_handler.tauquantiles,\n",
    "            'description': output_handler.description\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "            'animal': animal,\n",
    "            'area': area,\n",
    "            'state': state,\n",
    "            'day': day,\n",
    "            'epoch': epoch,\n",
    "            'time_chunk': time_chunk,\n",
    "            'original_data': original_data_json,\n",
    "            'tau': output_handler.tau,\n",
    "            'branching_factor': output_handler.mre,\n",
    "        }\n",
    "\n",
    "        # Merge the additional data into the main data dictionary\n",
    "        data.update(additional_data)\n",
    "\n",
    "        #Add covariance matrix after conversion\n",
    "        data['pcov'] = json.dumps(data['pcov'])\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame([data])\n",
    "\n",
    "        # Save individual time_chunk to disk\n",
    "        directory = \"/home/dekorvyb/Documents/gov_CA3/\"\n",
    "        \n",
    "        file_name = f'{directory}_{animal}_{area}_{state}_{day}_{epoch}_{time_chunk}.parquet'\n",
    "        df.to_parquet(file_name, index=True)\n",
    "                            \n",
    "\n",
    "def compute_rk_and_tau_from_splitted_by_sec_spike_dict_trial_seperated(spike_dict, animal, area): # this function may need updating\n",
    "    states = spike_dict.keys()\n",
    "    days = list(set(day for state in states for day in spike_dict[state].keys()))\n",
    "    epochs = list(set(epoch for state in states for day in days if day in spike_dict[state] for epoch in spike_dict[state][day].keys()))\n",
    "    time_chunks = list(set(time_chunk for state in states for day in days if day in spike_dict[state] for epoch in epochs if epoch in spike_dict[state][day] for time_chunk in spike_dict[state][day][epoch].keys()))\n",
    "    \n",
    "    total_time_chunks = len(time_chunks)\n",
    "    #progress_bar = tqdm(total=total_time_chunks, desc=\"Processing\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}')\n",
    "    \n",
    "    for state, day, epoch, time_chunk in product(states, days, epochs, time_chunks):\n",
    "        if state in spike_dict and day in spike_dict[state] and epoch in spike_dict[state][day] and time_chunk in spike_dict[state][day][epoch]:\n",
    "            try:\n",
    "                process_time_chunk(spike_dict = spike_dict, state = state, day = day, epoch = epoch, time_chunk = time_chunk, animal = animal, area = area, method = 'ts')\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing for state: {state}, day: {day}, epoch; {epoch}. Error: {e}\")\n",
    "                continue\n",
    "                \n",
    "            gc.collect()\n",
    "            \n",
    "    #progress_bar.close()\n",
    "    return ('Finished and saved to disk')\n",
    "\n",
    "def compute_rk_and_tau_from_splitted_by_sec_spike_dict_stationary_mean(spike_dict, animal, area): # this function may need updating\n",
    "    states = spike_dict.keys()\n",
    "    days = list(set(day for state in states for day in spike_dict[state].keys()))\n",
    "    epochs = list(set(epoch for state in states for day in days if day in spike_dict[state] for epoch in spike_dict[state][day].keys()))\n",
    "    \n",
    "    \n",
    "    for state, day, epoch  in product(states, days, epochs):\n",
    "        if state in spike_dict and day in spike_dict[state] and epoch in spike_dict[state][day]:\n",
    "            try:\n",
    "                process_time_chunk(spike_dict = spike_dict, state = state, day = day, epoch = epoch, animal = animal, area = area, method = 'sm', time_chunk = None)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing for state: {state}, day: {day}, epoch; {epoch}. Error: {e}\")\n",
    "                continue\n",
    "                \n",
    "            \n",
    "            gc.collect()\n",
    "            \n",
    "    return ('Finished and saved to disk')\n",
    "\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def intrinsic_time_scale_estimation(animal, area, len_time_chunk):\n",
    "    neuron_ids = compact.neuron_ids_for_specific_animal_and_subarea(area, animal)\n",
    "    #print(neuron_ids)\n",
    "    splitted_by_sec_spike_dict = compact.get_spike_data(neuron_ids, len_time_chunk, area, animal)\n",
    "    compute_rk_and_tau_from_splitted_by_sec_spike_dict_trial_seperated(splitted_by_sec_spike_dict, animal, area)\n",
    "    return 'Done'\n",
    "\n",
    "def intrinsic_time_scale_estimation_for_all_animals(animal_list, area_list, len_time_chunk):\n",
    "    for animal in animal_list:\n",
    "        for area in area_list:\n",
    "            \n",
    "            #try:\n",
    "                # Attempt to run the estimation function for each combination\n",
    "            print(f\"Processing for animal: {animal}, area: {area}\")\n",
    "            intrinsic_time_scale_estimation(animal, area, len_time_chunk)\n",
    "            \n",
    "            #except Exception as e:\n",
    "             #   # If an error occurs, print the error message and continue with the next combination\n",
    "                #print(f\"Error processing for animal: {animal}, area: {area}. Error: {e}\")\n",
    "                \n",
    "    return 'All combinations processed'\n",
    "\n",
    "animal_list = [ \"bon\"]#'egy', 'con', 'dav', 'fra', 'gov', 'remy', 'bon', 'dud', 'Cor', \"Fiv\"\n",
    "area_list = ['CA1']\n",
    "len_time_chunk = 90\n",
    "\n",
    "intrinsic_time_scale_estimation_for_all_animals(animal_list, area_list, len_time_chunk)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#dav ca3 done\n",
    "#cor ca1 done\n",
    "#rest not yet\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442d194-f737-4b6e-9a55-9fb7dae08348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d5c87-1a0c-487a-b54a-cc9cd972b9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9eaaf-80b6-4f53-b6c2-e52d3499ec70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
