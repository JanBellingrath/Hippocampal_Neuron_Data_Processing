{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570c47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import dask\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from collections import namedtuple\n",
    "import mrestimator as mre\n",
    "\n",
    "import loren_frank_data_processing\n",
    "from loren_frank_data_processing.core import get_data_filename, logger, get_epochs, get_data_structure\n",
    "from loren_frank_data_processing.tetrodes import get_trial_time\n",
    "from loren_frank_data_processing.neurons import get_spikes_dataframe, make_neuron_dataframe, convert_neuron_epoch_to_dataframe, _add_to_dict, _get_neuron_id\n",
    "import loren_frank_data_processing.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c98b9b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Animal = namedtuple('Animal', {'directory', 'short_name'})\n",
    "conley = Animal('C:\\\\Users\\janbe\\Downloads\\Conley.tar\\Conley', 'con')\n",
    "corriander = Animal('C:\\\\Users\\janbe\\Downloads\\Corriander.tar\\Corriander', 'Cor')\n",
    "animals = {'con': Animal('con','C:\\\\Users\\\\janbe\\\\Downloads\\\\Conley.tar\\\\Conley'), 'Cor': Animal('Cor','C:\\\\Users\\janbe\\Downloads\\Corriander.tar\\Corriander')} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0affafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following functions from 'loren_frank_data_processing'got modified, with changes indicated\n",
    "\n",
    "def convert_neuron_epoch_to_dataframe_modified(tetrodes_in_epoch, animal, day, epoch):\n",
    "    '''\n",
    "    Given an neuron data structure, return a cleaned up DataFrame\n",
    "    '''\n",
    "    DROP_COLUMNS = ['ripmodtag', 'thetamodtag', 'runripmodtag',\n",
    "                    'postsleepripmodtag', 'presleepripmodtag',\n",
    "                    'runthetamodtag', 'ripmodtag2', 'runripmodtag2',\n",
    "                    'postsleepripmodtag2', 'presleepripmodtag2',\n",
    "                    'ripmodtype', 'runripmodtype', 'postsleepripmodtype',\n",
    "                    'presleepripmodtype', 'FStag', 'ripmodtag3',\n",
    "                    'runripmodtag3', 'ripmodtype3', 'runripmodtype3',\n",
    "                    'tag', 'typetag', 'runripmodtype2',\n",
    "                    'tag2', 'ripmodtype2', 'descrip']\n",
    "\n",
    "    NEURON_INDEX = ['animal', 'day', 'epoch',\n",
    "                    'tetrode_number', 'neuron_number']\n",
    "\n",
    "    neuron_dict_list = [_add_to_dict(\n",
    "        _convert_to_dict(neuron), tetrode_ind, neuron_ind)\n",
    "        for tetrode_ind, tetrode in enumerate(\n",
    "        tetrodes_in_epoch[0][0])\n",
    "        for neuron_ind, neuron in enumerate(tetrode[0])\n",
    "        #if neuron.size > 0\n",
    "    ]\n",
    "    try:\n",
    "        return (pd.DataFrame(neuron_dict_list)\n",
    "                  .drop(DROP_COLUMNS, axis=1, errors='ignore')\n",
    "                  .assign(animal=animal)\n",
    "                \n",
    "                  .assign(day=day)\n",
    "                  .assign(epoch=epoch)\n",
    "                  .assign(neuron_id=_get_neuron_id\n",
    "                         )\n",
    "                # set index to identify rows\n",
    "                  .set_index(NEURON_INDEX)\n",
    "                  .sort_index())\n",
    "    except AttributeError:\n",
    "        logger.debug(f'Neuron info {animal}, {day}, {epoch} not processed')\n",
    "\n",
    "def _convert_to_dict_modified(struct_array):\n",
    "    try:\n",
    "        return {name: struct_array[name].item().item()\n",
    "                for name in struct_array.dtype.names\n",
    "                if struct_array[name].item().size == 1}\n",
    "    except TypeError:\n",
    "        return {}\n",
    "    #added in the AttributeError\n",
    "    except AttributeError:\n",
    "        return {}\n",
    "    \n",
    "def get_spike_indicator_dataframe_modified(neuron_key, animals, time_function=get_trial_time):\n",
    "    time = time_function(neuron_key[:3], animals)\n",
    "    spikes_df = get_spikes_dataframe(neuron_key, animals)\n",
    "    time_index = None\n",
    "    try:\n",
    "        time_index = np.digitize(spikes_df.index.total_seconds(),\n",
    "                             time.total_seconds())\n",
    " \n",
    "        time_index[time_index >= len(time)] = len(time) -1\n",
    "    #the exception is for empty data\n",
    "    except AttributeError: \n",
    "        print('No spikes here; data is emtpy')\n",
    "    \n",
    "    #the following accounts for an empty time_index\n",
    "    if time_index is not None:\n",
    "        return (spikes_df.groupby(time[time_index]).sum().reindex(index=time, fill_value=0))\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "def make_neuron_dataframe_modified(animals):\n",
    "    '''Information about all recorded neurons such as brain area.\n",
    "    The index of the dataframe corresponds to the unique key for that neuron\n",
    "    and can be used to load spiking information.\n",
    "    Parameters\n",
    "    ----------\n",
    "    animals : dict of named-tuples\n",
    "        Dictionary containing information about the directory for each\n",
    "        animal. The key is the animal_short_name.\n",
    "    Returns\n",
    "    -------\n",
    "    neuron_information : pandas.DataFrame\n",
    "    '''\n",
    "    #neuron_file_names = [(get_neuron_info_path(animals[animal]), animal)\n",
    "     #                    for animal in animals]\n",
    "    neuron_file_names = ['C:\\\\Users\\janbe\\Downloads\\Conley.tar\\Conley\\concellinfo.mat', 'C:\\\\Users\\janbe\\Downloads\\Corriander.tar\\Corriander\\Corcellinfo.mat']\n",
    "    neuron_data = [(loadmat(file_name), animal_name) for animal_name, file_name in zip(animals.keys(), neuron_file_names)]\n",
    "\n",
    "    return pd.concat([\n",
    "        convert_neuron_epoch_to_dataframe(\n",
    "            epoch, animal, day_ind + 1, epoch_ind + 1)\n",
    "        for cellfile, animal in neuron_data\n",
    "        for day_ind, day in enumerate(cellfile['cellinfo'].T)\n",
    "        for epoch_ind, epoch in enumerate(day[0].T)\n",
    "    ]).sort_index()\n",
    "\n",
    "#modified for access with correct name\n",
    "def get_tetrode_info_path_modified(animal):\n",
    "    '''Returns the Matlab tetrode info file name assuming it is in the\n",
    "    Raw Data directory.\n",
    "    Parameters\n",
    "    ----------\n",
    "    animal : namedtuple\n",
    "        First element is the directory where the animal's data is located.\n",
    "        The second element is the animal shortened name.\n",
    "    Returns\n",
    "    -------\n",
    "    filename : str\n",
    "        The path to the information about the tetrodes for a given animal.\n",
    "    '''\n",
    "    filename = '{animal}tetinfo'.format(animal=animal.short_name)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1232967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new functions \n",
    "\n",
    "#sums 2DArray of trials over time, over all trials, such that one cummulative time-series results\n",
    "def sum_time_series_dict(time_series_dict):\n",
    "    \n",
    "    num_bins = max([len(x) for x in time_series_dict.values() if x is not None])\n",
    "    res = np.zeros(num_bins)\n",
    "    for arr in time_series_dict.values():\n",
    "        if arr is not None:\n",
    "            res[:len(arr)] += arr\n",
    "    return res\n",
    "\n",
    "#generates dictionary of time-series, relative to neuron_key_list (indeces) given as input\n",
    "def generate_spike_indicator_dict(neuron_key_list, animals):\n",
    "    spike_indicator_dict = {}\n",
    "    for neuron_key_str in neuron_key_list:\n",
    "        animal_short_name, day_number, epoch_number, tetrode_number, neuron_number = neuron_key_str.split(\"_\")\n",
    "        neuron_key = (animal_short_name, int(day_number), int(epoch_number), int(tetrode_number), int(neuron_number))\n",
    "        try:\n",
    "            spike_indicator_array = get_spike_indicator_dataframe_modified(neuron_key, animals).values\n",
    "        except AttributeError:\n",
    "            spike_indicator_array = None\n",
    "            print(f\"No spike indicator data for neuron: {neuron_key}\")\n",
    "        spike_indicator_dict[neuron_key] = spike_indicator_array\n",
    "    return spike_indicator_dict\n",
    "\n",
    "\n",
    "def split_neuron_dataframe_informationally(df, split_cols):\n",
    "    '''Splits a DataFrame into multiple DataFrames based on specified\n",
    "    column values.\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to be split.\n",
    "    split_cols : list of str\n",
    "        The names of the columns to use for splitting the DataFrame.\n",
    "    Returns\n",
    "    -------\n",
    "    dfs : dict\n",
    "        A dictionary containing the split DataFrames. The keys are tuples\n",
    "        containing the unique combinations of the specified column values.\n",
    "    '''\n",
    "    dfs = {}\n",
    "    for idx, group in df.groupby(split_cols):\n",
    "        dfs[idx] = group.copy()\n",
    "    return dfs\n",
    "\n",
    "def merge_dicts(dict_list):\n",
    "    merged_dict = {}\n",
    "    for dictionary in dict_list:\n",
    "        merged_dict.update(dictionary)\n",
    "    return merged_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
